{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    train_stats里面没有总氮数据，五个输入后缀为i，四个输出后缀为e，365天数据\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 设置打印最大行\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "\n",
    "# 导入数据\n",
    "dataset_path = \"./2019data.xlsx\"\n",
    "column_names = ['data', 'volume', 'CODi', 'BODi', 'SSi', 'NH3-Ni', \n",
    "                'TPi', 'TNi', 'CODe', 'BODe', 'SSe', 'NH3Ne', 'TPe',\n",
    "                'TNe', 'T', 'rain']\n",
    "rawdata = pd.read_excel(dataset_path, names=column_names)\n",
    "\n",
    "\n",
    "# 将降雨中的空值转化为0\n",
    "rawdata = rawdata.replace(np.NaN, 0)\n",
    "# data = data.fillna(0)\n",
    "\n",
    "\n",
    "# 删除相关性较差列数据及时间列\n",
    "del rawdata['data']\n",
    "del rawdata['BODi']\n",
    "del rawdata['BODe']\n",
    "del rawdata['rain']\n",
    "\n",
    "\n",
    "# 将总氮数据提出来\n",
    "TNe = rawdata.pop('TNe')\n",
    "\n",
    "\n",
    "# 输入指标归一化\n",
    "rawdata_stats = rawdata.describe()\n",
    "train_stats = rawdata_stats.transpose()\n",
    "train_stats\n",
    "'''\n",
    "    train_stats里面没有总氮数据，五个输入后缀为i，四个输出后缀为e，365天数据\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>TNe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.30031852048560087, -0.17806441681418544, 0...</td>\n",
       "      <td>10.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.20807792529663297, 0.171670752694157, 0.27...</td>\n",
       "      <td>8.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.09723305059198947, -0.7503583305551095, -...</td>\n",
       "      <td>8.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.0062510990020931126, -0.9623190393480442,...</td>\n",
       "      <td>9.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.2875522782664631, 0.6273862765989668, -0.4...</td>\n",
       "      <td>9.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[0.22938496336660016, 0.09748450461662982, 0....</td>\n",
       "      <td>9.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[0.0930019390959739, -0.5383976217621746, -0....</td>\n",
       "      <td>8.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[0.1306713439538475, -1.6299952720457889, -1....</td>\n",
       "      <td>9.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[0.08553998061577633, 0.06569039829768959, -0...</td>\n",
       "      <td>9.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[0.23028399450879072, -0.3264369129692398, 0....</td>\n",
       "      <td>9.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[0.13921213980467692, -1.0259072519859247, -0...</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[0.1588110187044757, -1.4498286695717943, -1....</td>\n",
       "      <td>8.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[0.34491046513835455, -1.386240456933914, -1....</td>\n",
       "      <td>7.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[0.4248343336792799, -0.9941131456669845, -0....</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[[0.26741398068134997, 0.6167882411593201, 0.6...</td>\n",
       "      <td>7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[[0.09974467266241901, 0.5637980639610864, 0.4...</td>\n",
       "      <td>8.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[[-0.16385125822846436, 0.3836314614870918, 1....</td>\n",
       "      <td>7.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[[-0.057675680335512514, 1.4752291117707061, 1...</td>\n",
       "      <td>8.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[[-1.04723925854696, 0.06569039829768959, 0.43...</td>\n",
       "      <td>7.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[[-1.5009802760115911, 1.0513076941848365, 1.8...</td>\n",
       "      <td>8.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[[-0.8847843311527488, -0.3264369129692398, -0...</td>\n",
       "      <td>8.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[[-0.9380968778847731, -0.3264369129692398, 0....</td>\n",
       "      <td>8.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[[-1.2099638952838303, -0.39002512560712027, 0...</td>\n",
       "      <td>8.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[[-1.31524044203459, -0.17806441681418544, -0....</td>\n",
       "      <td>10.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[[-1.2564438053351905, 0.30944521340956466, 0....</td>\n",
       "      <td>8.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[[-1.824271874744066, -0.28404477121065286, -0...</td>\n",
       "      <td>9.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[[-1.305261196356251, 0.24585700077168418, 0.4...</td>\n",
       "      <td>7.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[[-1.5270521791351779, 1.4752291117707061, 0.5...</td>\n",
       "      <td>6.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[[-2.200876020208567, 1.9415426711151627, 1.88...</td>\n",
       "      <td>7.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[[-2.1817266568798637, -0.7079661887965225, -0...</td>\n",
       "      <td>6.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>[[-0.05704635853597753, -1.3226522442960333, -...</td>\n",
       "      <td>7.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>[[0.005885821417508098, -0.10387816873665826, ...</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>[[-1.2883594108830285, 0.8075528790729615, -0....</td>\n",
       "      <td>7.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>[[-1.603559729335771, -0.5489956572018213, -0....</td>\n",
       "      <td>8.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>[[0.8972751989015174, -0.42181923192606047, -0...</td>\n",
       "      <td>8.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>[[1.3689069360957802, 0.23525896533203744, 0.2...</td>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>[[1.1586235519369212, -1.3120542088563867, -1....</td>\n",
       "      <td>9.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>[[1.1368669982958588, -0.3794270901674735, -0....</td>\n",
       "      <td>9.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>[[0.843782845941055, -0.8987308267101638, -0.9...</td>\n",
       "      <td>7.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>[[0.7451591296425213, 0.5108078867628527, 0.67...</td>\n",
       "      <td>6.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>[[0.7455187420993975, -1.375642421494267, -1.0...</td>\n",
       "      <td>8.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>[[0.07933666573464555, -0.35823101928818, -0.5...</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>[[-0.5002687116369534, -0.9623190393480442, -0...</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>[[0.05254553769730639, -0.8351426140722834, -0...</td>\n",
       "      <td>8.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>[[0.3501248457630725, -1.6299952720457889, -1....</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>[[0.39570572467223897, -0.888132791270517, -0....</td>\n",
       "      <td>7.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>[[0.4289698769333661, -0.8245445786326366, -0....</td>\n",
       "      <td>6.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>[[0.20475151007052153, -0.3476329838485333, -0...</td>\n",
       "      <td>6.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>[[1.1744465000395101, -0.3794270901674735, -0....</td>\n",
       "      <td>6.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>[[0.5724552472273137, -0.6973681533568757, -1....</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>[[0.6790803406913624, -0.5489956572018213, -0....</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>[[1.2603938772331282, -0.2734467357710061, -0....</td>\n",
       "      <td>6.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>[[1.2816110121888764, -1.1954758190202726, -0....</td>\n",
       "      <td>6.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>[[1.252392500067613, -1.502818846770028, -1.24...</td>\n",
       "      <td>5.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>[[0.9641631158806511, -0.42181923192606047, 0....</td>\n",
       "      <td>6.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>[[0.35066426444838683, 0.16107271725451025, -0...</td>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>[[-0.2798262755713172, -1.4816227758907345, -1...</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>[[-0.17625788799072273, -0.6125838698397018, -...</td>\n",
       "      <td>8.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>[[0.02629382834528156, -0.9093288621498106, -0...</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>[[0.41018012606154197, -0.019093885219484328, ...</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input    TNe\n",
       "0    [[0.30031852048560087, -0.17806441681418544, 0...  10.70\n",
       "1    [[0.20807792529663297, 0.171670752694157, 0.27...   8.89\n",
       "2    [[-0.09723305059198947, -0.7503583305551095, -...   8.95\n",
       "3    [[-0.0062510990020931126, -0.9623190393480442,...   9.07\n",
       "4    [[0.2875522782664631, 0.6273862765989668, -0.4...   9.37\n",
       "5    [[0.22938496336660016, 0.09748450461662982, 0....   9.01\n",
       "6    [[0.0930019390959739, -0.5383976217621746, -0....   8.34\n",
       "7    [[0.1306713439538475, -1.6299952720457889, -1....   9.11\n",
       "8    [[0.08553998061577633, 0.06569039829768959, -0...   9.41\n",
       "9    [[0.23028399450879072, -0.3264369129692398, 0....   9.03\n",
       "10   [[0.13921213980467692, -1.0259072519859247, -0...   8.97\n",
       "11   [[0.1588110187044757, -1.4498286695717943, -1....   8.76\n",
       "12   [[0.34491046513835455, -1.386240456933914, -1....   7.67\n",
       "13   [[0.4248343336792799, -0.9941131456669845, -0....   7.88\n",
       "14   [[0.26741398068134997, 0.6167882411593201, 0.6...   7.69\n",
       "15   [[0.09974467266241901, 0.5637980639610864, 0.4...   8.42\n",
       "16   [[-0.16385125822846436, 0.3836314614870918, 1....   7.71\n",
       "17   [[-0.057675680335512514, 1.4752291117707061, 1...   8.74\n",
       "18   [[-1.04723925854696, 0.06569039829768959, 0.43...   7.61\n",
       "19   [[-1.5009802760115911, 1.0513076941848365, 1.8...   8.42\n",
       "20   [[-0.8847843311527488, -0.3264369129692398, -0...   8.54\n",
       "21   [[-0.9380968778847731, -0.3264369129692398, 0....   8.38\n",
       "22   [[-1.2099638952838303, -0.39002512560712027, 0...   8.46\n",
       "23   [[-1.31524044203459, -0.17806441681418544, -0....  10.10\n",
       "24   [[-1.2564438053351905, 0.30944521340956466, 0....   8.83\n",
       "25   [[-1.824271874744066, -0.28404477121065286, -0...   9.11\n",
       "26   [[-1.305261196356251, 0.24585700077168418, 0.4...   7.53\n",
       "27   [[-1.5270521791351779, 1.4752291117707061, 0.5...   6.24\n",
       "28   [[-2.200876020208567, 1.9415426711151627, 1.88...   7.24\n",
       "29   [[-2.1817266568798637, -0.7079661887965225, -0...   6.02\n",
       "..                                                 ...    ...\n",
       "270  [[-0.05704635853597753, -1.3226522442960333, -...   7.76\n",
       "271  [[0.005885821417508098, -0.10387816873665826, ...   7.38\n",
       "272  [[-1.2883594108830285, 0.8075528790729615, -0....   7.72\n",
       "273  [[-1.603559729335771, -0.5489956572018213, -0....   8.60\n",
       "274  [[0.8972751989015174, -0.42181923192606047, -0...   8.86\n",
       "275  [[1.3689069360957802, 0.23525896533203744, 0.2...   9.50\n",
       "276  [[1.1586235519369212, -1.3120542088563867, -1....   9.72\n",
       "277  [[1.1368669982958588, -0.3794270901674735, -0....   9.04\n",
       "278  [[0.843782845941055, -0.8987308267101638, -0.9...   7.52\n",
       "279  [[0.7451591296425213, 0.5108078867628527, 0.67...   6.53\n",
       "280  [[0.7455187420993975, -1.375642421494267, -1.0...   8.48\n",
       "281  [[0.07933666573464555, -0.35823101928818, -0.5...   7.46\n",
       "282  [[-0.5002687116369534, -0.9623190393480442, -0...   8.00\n",
       "283  [[0.05254553769730639, -0.8351426140722834, -0...   8.22\n",
       "284  [[0.3501248457630725, -1.6299952720457889, -1....   8.50\n",
       "285  [[0.39570572467223897, -0.888132791270517, -0....   7.13\n",
       "286  [[0.4289698769333661, -0.8245445786326366, -0....   6.98\n",
       "287  [[0.20475151007052153, -0.3476329838485333, -0...   6.15\n",
       "288  [[1.1744465000395101, -0.3794270901674735, -0....   6.94\n",
       "289  [[0.5724552472273137, -0.6973681533568757, -1....   6.03\n",
       "290  [[0.6790803406913624, -0.5489956572018213, -0....   6.01\n",
       "291  [[1.2603938772331282, -0.2734467357710061, -0....   6.71\n",
       "292  [[1.2816110121888764, -1.1954758190202726, -0....   6.35\n",
       "293  [[1.252392500067613, -1.502818846770028, -1.24...   5.69\n",
       "294  [[0.9641631158806511, -0.42181923192606047, 0....   6.82\n",
       "295  [[0.35066426444838683, 0.16107271725451025, -0...   6.07\n",
       "296  [[-0.2798262755713172, -1.4816227758907345, -1...   8.50\n",
       "297  [[-0.17625788799072273, -0.6125838698397018, -...   8.10\n",
       "298  [[0.02629382834528156, -0.9093288621498106, -0...   5.91\n",
       "299  [[0.41018012606154197, -0.019093885219484328, ...   6.40\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm(x):\n",
    "    return (x - train_stats['mean'])/train_stats['std']\n",
    "\n",
    "\n",
    "# 归一化 可以用np函数，待修\n",
    "rawdata_norm = norm(rawdata)\n",
    "\n",
    "\n",
    "# 整理成RNN输入数据形式\n",
    "datanum = 300  # 使用数据组数////////////////////////////////////////////////////////////////////////////////////////\n",
    "lookback = 5  # 设置输入变量涵盖天数///////////////////////////////////////////////////////////////////////////////\n",
    "paranum = 11  # 设置输入变量的指标个数//////////////////////////////////////////////////////////////////////////////\n",
    "data = pd.DataFrame(columns=['input', 'TNe'])  # 建立新的数据矩阵\n",
    "parastr = ['volume', 'CODi', 'SSi', 'NH3-Ni', 'TPi', 'TNi', 'CODe', 'SSe', 'NH3Ne', 'TPe', 'T']\n",
    "\n",
    "\n",
    "# 可以简化，列表生成器\n",
    "for i in range(datanum):\n",
    "    Inputlist = []\n",
    "    for j in range(lookback):\n",
    "        inputlist = []\n",
    "        for k in range(paranum):\n",
    "            # inputlist为一天数据，11 para的顺序\n",
    "            inputlist.append(rawdata_norm.loc[i+j][parastr[k]])\n",
    "        # Inputlist为五天数据\n",
    "        Inputlist.append(inputlist)\n",
    "    # 每一行为五天数据向量，输出为五天后总氮输出\n",
    "    data.loc[i] = [Inputlist, TNe[i+lookback]]\n",
    "\n",
    "# 300 rows x 2 cols\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>TNe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>[[1.9352066525629286, -0.46421137368464743, -0...</td>\n",
       "      <td>7.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>[[-0.6848398051291051, -0.9199268975894572, -0...</td>\n",
       "      <td>7.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>[[0.3501248457630725, -1.6299952720457889, -1....</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>[[1.1368669982958588, -0.3794270901674735, -0....</td>\n",
       "      <td>9.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>[[0.2631885343130416, -0.44301530280535395, -0...</td>\n",
       "      <td>9.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>[[-1.4770660476292665, 0.36243539060779834, 0....</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>[[-0.27083596414938926, -0.9941131456669845, -...</td>\n",
       "      <td>9.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[[-4.016109799409743, 0.30944521340956466, 0.7...</td>\n",
       "      <td>8.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[[-0.1053243308717236, 1.1254939422623635, 0.7...</td>\n",
       "      <td>7.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[[0.7928976832929515, -1.5558090239682618, -1....</td>\n",
       "      <td>9.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[[-1.31524044203459, -0.17806441681418544, -0....</td>\n",
       "      <td>10.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[[-0.34824254549217637, -0.28404477121065286, ...</td>\n",
       "      <td>8.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>[[0.6790803406913624, -0.5489956572018213, -0....</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>[[-1.7445278124315788, 1.0831018005037767, 0.4...</td>\n",
       "      <td>9.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>[[-0.3567833413430074, 1.5706114307275267, 0.1...</td>\n",
       "      <td>7.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[[0.3294471294926419, 1.1254939422623635, 1.79...</td>\n",
       "      <td>8.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>[[-0.17625788799072273, -0.6125838698397018, -...</td>\n",
       "      <td>8.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>[[0.1639354962149746, -0.33703494840888654, -0...</td>\n",
       "      <td>9.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[[-0.8554759159172697, -0.46421137368464743, 0...</td>\n",
       "      <td>6.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>[[-1.2883594108830285, 0.8075528790729615, -0....</td>\n",
       "      <td>7.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>[[0.9215490397407199, -1.0788974291841584, -0....</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>[[1.7366106732525755, -0.8987308267101638, -0....</td>\n",
       "      <td>8.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>[[-1.9461804976253894, 0.033896291978749375, -...</td>\n",
       "      <td>9.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>[[-0.7101924833389378, 0.701572524676494, 1.61...</td>\n",
       "      <td>8.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>[[-0.43481924448532944, -0.2628487003313594, -...</td>\n",
       "      <td>7.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>[[1.1962929567947915, -0.4854074445639409, -0....</td>\n",
       "      <td>8.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>[[0.9326970259039082, -0.14627031049524522, -0...</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.20807792529663297, 0.171670752694157, 0.27...</td>\n",
       "      <td>8.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>[[-0.782564490285445, 0.7969548436333147, 0.31...</td>\n",
       "      <td>9.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[0.1588110187044757, -1.4498286695717943, -1....</td>\n",
       "      <td>8.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>[[0.2712798145927758, 1.4222389345724724, -0.0...</td>\n",
       "      <td>9.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>[[1.7167420850101165, -1.100093500063452, -1.1...</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>[[0.9961686245427083, -0.3688290547278268, 0.0...</td>\n",
       "      <td>8.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[[1.7527033306978217, -0.6655740470379355, -0....</td>\n",
       "      <td>8.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>[[-1.0110083035165978, 1.888552493916929, 1.08...</td>\n",
       "      <td>9.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[[0.7695228735959428, 1.0513076941848365, 1.50...</td>\n",
       "      <td>8.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>[[0.11035324014029309, 1.4752291117707061, 1.8...</td>\n",
       "      <td>7.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>[[-1.1406485942207774, 0.39422949692673853, 0....</td>\n",
       "      <td>9.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>[[-0.07979184643345281, 0.7863568081936679, 0....</td>\n",
       "      <td>7.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>[[2.013692071276349, 0.04449432741839612, -0.3...</td>\n",
       "      <td>8.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>[[-1.233158898752401, 0.39422949692673853, 0.9...</td>\n",
       "      <td>7.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>[[0.11143207751092495, 0.44721967412497227, -0...</td>\n",
       "      <td>9.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>[[0.43912892884014487, -0.4854074445639409, -0...</td>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[[0.16240714327324748, 0.2882491425302712, 1.0...</td>\n",
       "      <td>7.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>[[0.843782845941055, -0.8987308267101638, -0.9...</td>\n",
       "      <td>7.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[[0.0009411501354472808, 0.39422949692673853, ...</td>\n",
       "      <td>7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>[[-1.225337327815324, -0.44301530280535395, 0....</td>\n",
       "      <td>8.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>[[0.2889907280939712, 1.930944635675516, 0.610...</td>\n",
       "      <td>9.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[[1.0243982024075586, -1.4180345632528542, -0....</td>\n",
       "      <td>8.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>[[-1.499541826184083, 1.56001339528788, -0.015...</td>\n",
       "      <td>9.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>[[0.2592327972873968, 0.6167882411593201, -0.3...</td>\n",
       "      <td>8.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>[[2.283221607705703, -0.008495849779837588, 1....</td>\n",
       "      <td>9.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[[-1.824271874744066, -0.28404477121065286, -0...</td>\n",
       "      <td>9.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[[-0.16385125822846436, 0.3836314614870918, 1....</td>\n",
       "      <td>7.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>[[0.24601703949716375, 0.10808254005627656, -0...</td>\n",
       "      <td>9.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>[[0.5994261814930941, -0.972917074787691, -0.7...</td>\n",
       "      <td>8.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[[-0.37593270467171086, -0.6655740470379355, 0...</td>\n",
       "      <td>8.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>[[0.39570572467223897, -0.888132791270517, -0....</td>\n",
       "      <td>7.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>[[-0.563920116504193, 0.8393469853919017, -0.1...</td>\n",
       "      <td>8.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>[[0.08877649272766872, 0.415425567806032, 1.57...</td>\n",
       "      <td>6.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input    TNe\n",
       "240  [[1.9352066525629286, -0.46421137368464743, -0...   7.10\n",
       "80   [[-0.6848398051291051, -0.9199268975894572, -0...   7.75\n",
       "284  [[0.3501248457630725, -1.6299952720457889, -1....   8.50\n",
       "277  [[1.1368669982958588, -0.3794270901674735, -0....   9.04\n",
       "258  [[0.2631885343130416, -0.44301530280535395, -0...   9.63\n",
       "130  [[-1.4770660476292665, 0.36243539060779834, 0....  10.00\n",
       "204  [[-0.27083596414938926, -0.9941131456669845, -...   9.42\n",
       "36   [[-4.016109799409743, 0.30944521340956466, 0.7...   8.81\n",
       "66   [[-0.1053243308717236, 1.1254939422623635, 0.7...   7.67\n",
       "44   [[0.7928976832929515, -1.5558090239682618, -1....   9.18\n",
       "23   [[-1.31524044203459, -0.17806441681418544, -0....  10.10\n",
       "43   [[-0.34824254549217637, -0.28404477121065286, ...   8.32\n",
       "290  [[0.6790803406913624, -0.5489956572018213, -0....   6.01\n",
       "122  [[-1.7445278124315788, 1.0831018005037767, 0.4...   9.22\n",
       "184  [[-0.3567833413430074, 1.5706114307275267, 0.1...   7.10\n",
       "56   [[0.3294471294926419, 1.1254939422623635, 1.79...   8.65\n",
       "297  [[-0.17625788799072273, -0.6125838698397018, -...   8.10\n",
       "216  [[0.1639354962149746, -0.33703494840888654, -0...   9.22\n",
       "32   [[-0.8554759159172697, -0.46421137368464743, 0...   6.90\n",
       "272  [[-1.2883594108830285, 0.8075528790729615, -0....   7.72\n",
       "235  [[0.9215490397407199, -1.0788974291841584, -0....   8.50\n",
       "229  [[1.7366106732525755, -0.8987308267101638, -0....   8.42\n",
       "144  [[-1.9461804976253894, 0.033896291978749375, -...   9.26\n",
       "79   [[-0.7101924833389378, 0.701572524676494, 1.61...   8.29\n",
       "186  [[-0.43481924448532944, -0.2628487003313594, -...   7.74\n",
       "191  [[1.1962929567947915, -0.4854074445639409, -0....   8.39\n",
       "203  [[0.9326970259039082, -0.14627031049524522, -0...   9.95\n",
       "1    [[0.20807792529663297, 0.171670752694157, 0.27...   8.89\n",
       "133  [[-0.782564490285445, 0.7969548436333147, 0.31...   9.03\n",
       "11   [[0.1588110187044757, -1.4498286695717943, -1....   8.76\n",
       "..                                                 ...    ...\n",
       "198  [[0.2712798145927758, 1.4222389345724724, -0.0...   9.93\n",
       "188  [[1.7167420850101165, -1.100093500063452, -1.1...   8.00\n",
       "180  [[0.9961686245427083, -0.3688290547278268, 0.0...   8.06\n",
       "196  [[1.7527033306978217, -0.6655740470379355, -0....   8.89\n",
       "126  [[-1.0110083035165978, 1.888552493916929, 1.08...   9.05\n",
       "45   [[0.7695228735959428, 1.0513076941848365, 1.50...   8.24\n",
       "65   [[0.11035324014029309, 1.4752291117707061, 1.8...   7.95\n",
       "129  [[-1.1406485942207774, 0.39422949692673853, 0....   9.28\n",
       "236  [[-0.07979184643345281, 0.7863568081936679, 0....   7.49\n",
       "247  [[2.013692071276349, 0.04449432741839612, -0.3...   8.96\n",
       "166  [[-1.233158898752401, 0.39422949692673853, 0.9...   7.72\n",
       "233  [[0.11143207751092495, 0.44721967412497227, -0...   9.28\n",
       "201  [[0.43912892884014487, -0.4854074445639409, -0...   9.50\n",
       "97   [[0.16240714327324748, 0.2882491425302712, 1.0...   7.61\n",
       "278  [[0.843782845941055, -0.8987308267101638, -0.9...   7.52\n",
       "100  [[0.0009411501354472808, 0.39422949692673853, ...   7.07\n",
       "212  [[-1.225337327815324, -0.44301530280535395, 0....   8.61\n",
       "119  [[0.2889907280939712, 1.930944635675516, 0.610...   9.69\n",
       "53   [[1.0243982024075586, -1.4180345632528542, -0....   8.42\n",
       "163  [[-1.499541826184083, 1.56001339528788, -0.015...   9.88\n",
       "112  [[0.2592327972873968, 0.6167882411593201, -0.3...   8.77\n",
       "248  [[2.283221607705703, -0.008495849779837588, 1....   9.18\n",
       "25   [[-1.824271874744066, -0.28404477121065286, -0...   9.11\n",
       "16   [[-0.16385125822846436, 0.3836314614870918, 1....   7.71\n",
       "202  [[0.24601703949716375, 0.10808254005627656, -0...   9.28\n",
       "200  [[0.5994261814930941, -0.972917074787691, -0.7...   8.33\n",
       "94   [[-0.37593270467171086, -0.6655740470379355, 0...   8.23\n",
       "285  [[0.39570572467223897, -0.888132791270517, -0....   7.13\n",
       "86   [[-0.563920116504193, 0.8393469853919017, -0.1...   8.04\n",
       "61   [[0.08877649272766872, 0.415425567806032, 1.57...   6.83\n",
       "\n",
       "[240 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>TNe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.30031852048560087, -0.17806441681418544, 0...</td>\n",
       "      <td>10.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.2875522782664631, 0.6273862765989668, -0.4...</td>\n",
       "      <td>9.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[0.4248343336792799, -0.9941131456669845, -0....</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[[0.09974467266241901, 0.5637980639610864, 0.4...</td>\n",
       "      <td>8.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[[-1.04723925854696, 0.06569039829768959, 0.43...</td>\n",
       "      <td>7.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[[-0.9380968778847731, -0.3264369129692398, 0....</td>\n",
       "      <td>8.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[[-1.5270521791351779, 1.4752291117707061, 0.5...</td>\n",
       "      <td>6.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[[-0.0057116803167787805, 0.9559253752280158, ...</td>\n",
       "      <td>6.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[[-1.0214370647660322, 1.273866438417418, 1.77...</td>\n",
       "      <td>7.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[[-0.6111192514693072, -0.3264369129692398, -0...</td>\n",
       "      <td>8.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[[-1.9524737156207392, 0.5637980639610864, 0.6...</td>\n",
       "      <td>7.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[[0.7640387836285677, -1.947936335235191, -1.3...</td>\n",
       "      <td>6.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[[0.1428082643734487, -1.4922208113303812, -1....</td>\n",
       "      <td>8.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[[0.9619155380251683, -0.5701917280811148, -0....</td>\n",
       "      <td>8.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>[[0.03636297713783811, 1.1996801903398908, 1.6...</td>\n",
       "      <td>6.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>[[-0.06324967341710672, 2.789385506286902, 0.7...</td>\n",
       "      <td>8.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>[[0.6351177178381422, 0.7333666309954342, 0.31...</td>\n",
       "      <td>9.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>[[-0.5218454590495778, 1.4116408991328258, 1.8...</td>\n",
       "      <td>8.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[[-0.9392656183696241, 2.005130883753043, 1.34...</td>\n",
       "      <td>7.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>[[-0.417737652783669, -1.1318876063823922, -0....</td>\n",
       "      <td>6.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>[[-4.737222678562466, 3.9127772628894566, 4.63...</td>\n",
       "      <td>8.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[[-0.6994041096326256, 0.171670752694157, -0.6...</td>\n",
       "      <td>7.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>[[0.14946109482567158, 0.09748450461662982, -0...</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>[[0.23837527478852488, -0.23105459401241915, -...</td>\n",
       "      <td>7.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>[[0.4213281122247304, 0.8287489499522549, 1.30...</td>\n",
       "      <td>6.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>[[0.5845022645326958, 1.4222389345724724, -0.0...</td>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>[[0.2586034754878602, 0.13987664637521677, 0.4...</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>[[-1.2835945458294076, 1.231474296658831, 0.92...</td>\n",
       "      <td>10.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>[[-0.6236157843457847, 2.1852974862270376, -0....</td>\n",
       "      <td>9.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>[[-1.3624395769997026, -0.04028995609877781, -...</td>\n",
       "      <td>8.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>[[-1.283055127144093, 0.7651607373143745, -0.3...</td>\n",
       "      <td>9.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>[[0.35183300493323777, -1.0259072519859247, -0...</td>\n",
       "      <td>8.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>[[0.5243570811200073, 0.06569039829768959, -0....</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>[[-1.153954255125228, 0.09748450461662982, 0.5...</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>[[0.015415551524750317, 0.36243539060779834, 0...</td>\n",
       "      <td>8.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>[[1.3912029084221602, -0.35823101928818, -0.84...</td>\n",
       "      <td>8.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>[[1.6555180642267961, 0.171670752694157, -0.48...</td>\n",
       "      <td>9.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>[[1.4814656350982993, -1.6087992011664953, -1....</td>\n",
       "      <td>9.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[[-0.0931874104521224, 0.7227685955557875, -0....</td>\n",
       "      <td>9.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>[[0.007683883701892397, -0.04028995609877781, ...</td>\n",
       "      <td>9.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>[[-0.4008358673104467, -0.8457406495119301, -0...</td>\n",
       "      <td>10.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>[[-0.36954958356214196, -0.9517210039083975, -...</td>\n",
       "      <td>9.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>[[-0.4074886977626727, -0.42181923192606047, -...</td>\n",
       "      <td>10.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>[[-1.2268656807570526, -0.33703494840888654, -...</td>\n",
       "      <td>10.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>[[1.5249787423804244, -1.2060738544599192, -1....</td>\n",
       "      <td>8.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>[[1.3365418149768469, -0.9623190393480442, -0....</td>\n",
       "      <td>7.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>[[1.650033974259421, -1.6087992011664953, -1.4...</td>\n",
       "      <td>8.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>[[1.5563549292429482, 0.9135332334694288, 1.54...</td>\n",
       "      <td>9.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>[[2.1925992685726845, -1.2696620670977996, -1....</td>\n",
       "      <td>9.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>[[1.1389347699229002, 0.2564550362113309, 0.90...</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>[[-1.4220453417270753, -0.17806441681418544, -...</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>[[0.15251780070912904, 0.07628843373733633, 0....</td>\n",
       "      <td>9.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>[[0.25042229209390704, -1.672387413804376, -1....</td>\n",
       "      <td>9.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>[[-0.9247013138661035, 0.30944521340956466, -0...</td>\n",
       "      <td>8.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>[[-1.603559729335771, -0.5489956572018213, -0....</td>\n",
       "      <td>8.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>[[0.7455187420993975, -1.375642421494267, -1.0...</td>\n",
       "      <td>8.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>[[0.07933666573464555, -0.35823101928818, -0.5...</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>[[0.05254553769730639, -0.8351426140722834, -0...</td>\n",
       "      <td>8.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>[[1.2816110121888764, -1.1954758190202726, -0....</td>\n",
       "      <td>6.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>[[-0.2798262755713172, -1.4816227758907345, -1...</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input    TNe\n",
       "0    [[0.30031852048560087, -0.17806441681418544, 0...  10.70\n",
       "4    [[0.2875522782664631, 0.6273862765989668, -0.4...   9.37\n",
       "13   [[0.4248343336792799, -0.9941131456669845, -0....   7.88\n",
       "15   [[0.09974467266241901, 0.5637980639610864, 0.4...   8.42\n",
       "18   [[-1.04723925854696, 0.06569039829768959, 0.43...   7.61\n",
       "21   [[-0.9380968778847731, -0.3264369129692398, 0....   8.38\n",
       "27   [[-1.5270521791351779, 1.4752291117707061, 0.5...   6.24\n",
       "31   [[-0.0057116803167787805, 0.9559253752280158, ...   6.57\n",
       "39   [[-1.0214370647660322, 1.273866438417418, 1.77...   7.75\n",
       "40   [[-0.6111192514693072, -0.3264369129692398, -0...   8.95\n",
       "42   [[-1.9524737156207392, 0.5637980639610864, 0.6...   7.63\n",
       "46   [[0.7640387836285677, -1.947936335235191, -1.3...   6.83\n",
       "48   [[0.1428082643734487, -1.4922208113303812, -1....   8.18\n",
       "49   [[0.9619155380251683, -0.5701917280811148, -0....   8.87\n",
       "62   [[0.03636297713783811, 1.1996801903398908, 1.6...   6.55\n",
       "68   [[-0.06324967341710672, 2.789385506286902, 0.7...   8.39\n",
       "72   [[0.6351177178381422, 0.7333666309954342, 0.31...   9.23\n",
       "74   [[-0.5218454590495778, 1.4116408991328258, 1.8...   8.03\n",
       "78   [[-0.9392656183696241, 2.005130883753043, 1.34...   7.49\n",
       "81   [[-0.417737652783669, -1.1318876063823922, -0....   6.65\n",
       "85   [[-4.737222678562466, 3.9127772628894566, 4.63...   8.14\n",
       "91   [[-0.6994041096326256, 0.171670752694157, -0.6...   7.72\n",
       "93   [[0.14946109482567158, 0.09748450461662982, -0...   8.47\n",
       "102  [[0.23837527478852488, -0.23105459401241915, -...   7.95\n",
       "105  [[0.4213281122247304, 0.8287489499522549, 1.30...   6.60\n",
       "108  [[0.5845022645326958, 1.4222389345724724, -0.0...   9.35\n",
       "111  [[0.2586034754878602, 0.13987664637521677, 0.4...   8.75\n",
       "124  [[-1.2835945458294076, 1.231474296658831, 0.92...  10.40\n",
       "125  [[-0.6236157843457847, 2.1852974862270376, -0....   9.16\n",
       "140  [[-1.3624395769997026, -0.04028995609877781, -...   8.13\n",
       "143  [[-1.283055127144093, 0.7651607373143745, -0.3...   9.40\n",
       "146  [[0.35183300493323777, -1.0259072519859247, -0...   8.02\n",
       "160  [[0.5243570811200073, 0.06569039829768959, -0....   9.84\n",
       "165  [[-1.153954255125228, 0.09748450461662982, 0.5...   5.47\n",
       "174  [[0.015415551524750317, 0.36243539060779834, 0...   8.69\n",
       "181  [[1.3912029084221602, -0.35823101928818, -0.84...   8.02\n",
       "193  [[1.6555180642267961, 0.171670752694157, -0.48...   9.01\n",
       "194  [[1.4814656350982993, -1.6087992011664953, -1....   9.11\n",
       "199  [[-0.0931874104521224, 0.7227685955557875, -0....   9.17\n",
       "208  [[0.007683883701892397, -0.04028995609877781, ...   9.75\n",
       "210  [[-0.4008358673104467, -0.8457406495119301, -0...  10.20\n",
       "211  [[-0.36954958356214196, -0.9517210039083975, -...   9.24\n",
       "215  [[-0.4074886977626727, -0.42181923192606047, -...  10.20\n",
       "220  [[-1.2268656807570526, -0.33703494840888654, -...  10.10\n",
       "222  [[1.5249787423804244, -1.2060738544599192, -1....   8.55\n",
       "224  [[1.3365418149768469, -0.9623190393480442, -0....   7.75\n",
       "231  [[1.650033974259421, -1.6087992011664953, -1.4...   8.89\n",
       "243  [[1.5563549292429482, 0.9135332334694288, 1.54...   9.16\n",
       "249  [[2.1925992685726845, -1.2696620670977996, -1....   9.06\n",
       "252  [[1.1389347699229002, 0.2564550362113309, 0.90...   9.30\n",
       "255  [[-1.4220453417270753, -0.17806441681418544, -...   9.14\n",
       "256  [[0.15251780070912904, 0.07628843373733633, 0....   9.24\n",
       "267  [[0.25042229209390704, -1.672387413804376, -1....   9.22\n",
       "269  [[-0.9247013138661035, 0.30944521340956466, -0...   8.62\n",
       "273  [[-1.603559729335771, -0.5489956572018213, -0....   8.60\n",
       "280  [[0.7455187420993975, -1.375642421494267, -1.0...   8.48\n",
       "281  [[0.07933666573464555, -0.35823101928818, -0.5...   7.46\n",
       "283  [[0.05254553769730639, -0.8351426140722834, -0...   8.22\n",
       "292  [[1.2816110121888764, -1.1954758190202726, -0....   6.35\n",
       "296  [[-0.2798262755713172, -1.4816227758907345, -1...   8.50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(60, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 分割训练数据和测试数据\n",
    "fraction = 0.8  # 定义训练集、测试集切割比例//////////////////////////////////////////////////////////////////////////\n",
    "train_data = data.sample(frac=fraction)  # frac=0.8 means train data possess 80% of all\n",
    "# print(len(train_data))\n",
    "test_data = data.drop(train_data.index)\n",
    "# print(len(test_data))\n",
    "# 生成训练数据和测试数据，训练数据是240*5*7的数组  x7???\n",
    "trainnum = int(datanum * fraction)\n",
    "testnum = datanum - trainnum\n",
    "# traindata(240,5,11)\n",
    "traindata = np.zeros((trainnum, lookback, paranum))\n",
    "# testdata(60,5,11)\n",
    "testdata = np.zeros((testnum, lookback, paranum))\n",
    "\n",
    "display(train_data)\n",
    "display(test_data)\n",
    "display(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 5, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(60, 5, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(trainnum):\n",
    "    for j in range(lookback):\n",
    "        for k in range(paranum):\n",
    "            traindata[i][j][k] = train_data.iloc[i, 0][j][k]\n",
    "for i in range(testnum):\n",
    "    for j in range(lookback):\n",
    "        for k in range(paranum):\n",
    "            testdata[i][j][k] = test_data.iloc[i, 0][j][k]\n",
    "\n",
    "# (240,5,11)\n",
    "display(traindata.shape)\n",
    "# (60,5,11)\n",
    "display(testdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 5, 32)             4224      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 10,497\n",
      "Trainable params: 10,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 192 samples, validate on 48 samples\n",
      "Epoch 1/400\n",
      "192/192 [==============================] - 2s 9ms/step - loss: 8.8325 - val_loss: 6.4535\n",
      "Epoch 2/400\n",
      "192/192 [==============================] - 0s 218us/step - loss: 5.8994 - val_loss: 4.9605\n",
      "Epoch 3/400\n",
      "192/192 [==============================] - 0s 156us/step - loss: 4.5581 - val_loss: 4.1356\n",
      "Epoch 4/400\n",
      "192/192 [==============================] - 0s 244us/step - loss: 3.7729 - val_loss: 3.5084\n",
      "Epoch 5/400\n",
      "192/192 [==============================] - 0s 208us/step - loss: 3.1799 - val_loss: 2.9883\n",
      "Epoch 6/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 2.6880 - val_loss: 2.5327\n",
      "Epoch 7/400\n",
      "192/192 [==============================] - 0s 395us/step - loss: 2.2639 - val_loss: 2.1410\n",
      "Epoch 8/400\n",
      "192/192 [==============================] - 0s 348us/step - loss: 1.9031 - val_loss: 1.7744\n",
      "Epoch 9/400\n",
      "192/192 [==============================] - 0s 218us/step - loss: 1.5813 - val_loss: 1.4618\n",
      "Epoch 10/400\n",
      "192/192 [==============================] - 0s 244us/step - loss: 1.3350 - val_loss: 1.2218\n",
      "Epoch 11/400\n",
      "192/192 [==============================] - 0s 239us/step - loss: 1.1563 - val_loss: 1.0281\n",
      "Epoch 12/400\n",
      "192/192 [==============================] - 0s 161us/step - loss: 1.0210 - val_loss: 0.9098\n",
      "Epoch 13/400\n",
      "192/192 [==============================] - 0s 260us/step - loss: 0.9591 - val_loss: 0.8260\n",
      "Epoch 14/400\n",
      "192/192 [==============================] - 0s 171us/step - loss: 0.9167 - val_loss: 0.7673\n",
      "Epoch 15/400\n",
      "192/192 [==============================] - 0s 187us/step - loss: 0.8884 - val_loss: 0.7334\n",
      "Epoch 16/400\n",
      "192/192 [==============================] - 0s 312us/step - loss: 0.8717 - val_loss: 0.7248\n",
      "Epoch 17/400\n",
      "192/192 [==============================] - 0s 203us/step - loss: 0.8643 - val_loss: 0.7207\n",
      "Epoch 18/400\n",
      "192/192 [==============================] - 0s 306us/step - loss: 0.8622 - val_loss: 0.7191\n",
      "Epoch 19/400\n",
      "192/192 [==============================] - 0s 322us/step - loss: 0.8601 - val_loss: 0.7190\n",
      "Epoch 20/400\n",
      "192/192 [==============================] - 0s 171us/step - loss: 0.8585 - val_loss: 0.7169\n",
      "Epoch 21/400\n",
      "192/192 [==============================] - 0s 260us/step - loss: 0.8592 - val_loss: 0.7161\n",
      "Epoch 22/400\n",
      "192/192 [==============================] - 0s 223us/step - loss: 0.8560 - val_loss: 0.7161\n",
      "Epoch 23/400\n",
      "192/192 [==============================] - ETA: 0s - loss: 0.843 - 0s 187us/step - loss: 0.8521 - val_loss: 0.7182\n",
      "Epoch 24/400\n",
      "192/192 [==============================] - 0s 260us/step - loss: 0.8508 - val_loss: 0.7175\n",
      "Epoch 25/400\n",
      "192/192 [==============================] - 0s 265us/step - loss: 0.8520 - val_loss: 0.7234\n",
      "Epoch 26/400\n",
      "192/192 [==============================] - 0s 291us/step - loss: 0.8499 - val_loss: 0.7317\n",
      "Epoch 27/400\n",
      "192/192 [==============================] - ETA: 0s - loss: 0.919 - 0s 182us/step - loss: 0.8545 - val_loss: 0.7357\n",
      "Epoch 28/400\n",
      "192/192 [==============================] - 0s 208us/step - loss: 0.8527 - val_loss: 0.7358\n",
      "Epoch 29/400\n",
      "192/192 [==============================] - 0s 291us/step - loss: 0.8434 - val_loss: 0.7156\n",
      "Epoch 30/400\n",
      "192/192 [==============================] - 0s 743us/step - loss: 0.8368 - val_loss: 0.7119\n",
      "Epoch 31/400\n",
      "192/192 [==============================] - 0s 779us/step - loss: 0.8350 - val_loss: 0.7158\n",
      "Epoch 32/400\n",
      "192/192 [==============================] - 0s 286us/step - loss: 0.8299 - val_loss: 0.7455\n",
      "Epoch 33/400\n",
      "192/192 [==============================] - 0s 483us/step - loss: 0.8411 - val_loss: 0.7260\n",
      "Epoch 34/400\n",
      "192/192 [==============================] - 0s 327us/step - loss: 0.8240 - val_loss: 0.7238\n",
      "Epoch 35/400\n",
      "192/192 [==============================] - 0s 774us/step - loss: 0.8263 - val_loss: 0.7031\n",
      "Epoch 36/400\n",
      "192/192 [==============================] - 0s 353us/step - loss: 0.8241 - val_loss: 0.7177\n",
      "Epoch 37/400\n",
      "192/192 [==============================] - 0s 317us/step - loss: 0.8139 - val_loss: 0.7071\n",
      "Epoch 38/400\n",
      "192/192 [==============================] - 0s 400us/step - loss: 0.8305 - val_loss: 0.7152\n",
      "Epoch 39/400\n",
      "192/192 [==============================] - 0s 364us/step - loss: 0.8087 - val_loss: 0.7316\n",
      "Epoch 40/400\n",
      "192/192 [==============================] - 0s 348us/step - loss: 0.8400 - val_loss: 0.8001\n",
      "Epoch 41/400\n",
      "192/192 [==============================] - 0s 395us/step - loss: 0.8236 - val_loss: 0.7082\n",
      "Epoch 42/400\n",
      "192/192 [==============================] - 0s 244us/step - loss: 0.8006 - val_loss: 0.8857\n",
      "Epoch 43/400\n",
      "192/192 [==============================] - 0s 312us/step - loss: 0.9258 - val_loss: 0.7251\n",
      "Epoch 44/400\n",
      "192/192 [==============================] - 0s 187us/step - loss: 0.7956 - val_loss: 0.7071\n",
      "Epoch 45/400\n",
      "192/192 [==============================] - 0s 260us/step - loss: 0.7829 - val_loss: 0.7308\n",
      "Epoch 46/400\n",
      "192/192 [==============================] - 0s 249us/step - loss: 0.7808 - val_loss: 0.7566\n",
      "Epoch 47/400\n",
      "192/192 [==============================] - 0s 270us/step - loss: 0.7719 - val_loss: 0.6859\n",
      "Epoch 48/400\n",
      "192/192 [==============================] - 0s 509us/step - loss: 0.7491 - val_loss: 0.7601\n",
      "Epoch 49/400\n",
      "192/192 [==============================] - 0s 296us/step - loss: 0.7960 - val_loss: 0.7124\n",
      "Epoch 50/400\n",
      "192/192 [==============================] - 0s 327us/step - loss: 0.7428 - val_loss: 0.6888\n",
      "Epoch 51/400\n",
      "192/192 [==============================] - 0s 244us/step - loss: 0.7517 - val_loss: 0.7981\n",
      "Epoch 52/400\n",
      "192/192 [==============================] - 0s 265us/step - loss: 0.8291 - val_loss: 0.6599\n",
      "Epoch 53/400\n",
      "192/192 [==============================] - 0s 260us/step - loss: 0.7321 - val_loss: 0.6615\n",
      "Epoch 54/400\n",
      "192/192 [==============================] - 0s 192us/step - loss: 0.7230 - val_loss: 0.6552\n",
      "Epoch 55/400\n",
      "192/192 [==============================] - 0s 218us/step - loss: 0.7256 - val_loss: 0.6397\n",
      "Epoch 56/400\n",
      "192/192 [==============================] - 0s 208us/step - loss: 0.7625 - val_loss: 0.7089\n",
      "Epoch 57/400\n",
      "192/192 [==============================] - 0s 229us/step - loss: 0.7704 - val_loss: 0.7270\n",
      "Epoch 58/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 0s 390us/step - loss: 0.7138 - val_loss: 0.6754\n",
      "Epoch 59/400\n",
      "192/192 [==============================] - 0s 296us/step - loss: 0.6894 - val_loss: 0.6443\n",
      "Epoch 60/400\n",
      "192/192 [==============================] - 0s 197us/step - loss: 0.6764 - val_loss: 0.6902\n",
      "Epoch 61/400\n",
      "192/192 [==============================] - 0s 203us/step - loss: 0.7881 - val_loss: 0.6983\n",
      "Epoch 62/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.7167 - val_loss: 0.6719\n",
      "Epoch 63/400\n",
      "192/192 [==============================] - 0s 192us/step - loss: 0.6734 - val_loss: 0.7035\n",
      "Epoch 64/400\n",
      "192/192 [==============================] - 0s 244us/step - loss: 0.7016 - val_loss: 0.6536\n",
      "Epoch 65/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.6456 - val_loss: 0.6483\n",
      "Epoch 66/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.6348 - val_loss: 0.6312\n",
      "Epoch 67/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.6799 - val_loss: 0.6938\n",
      "Epoch 68/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.7316 - val_loss: 0.6281\n",
      "Epoch 69/400\n",
      "192/192 [==============================] - 0s 187us/step - loss: 0.6290 - val_loss: 0.7017\n",
      "Epoch 70/400\n",
      "192/192 [==============================] - 0s 218us/step - loss: 0.6822 - val_loss: 0.6621\n",
      "Epoch 71/400\n",
      "192/192 [==============================] - 0s 223us/step - loss: 0.6304 - val_loss: 0.6360\n",
      "Epoch 72/400\n",
      "192/192 [==============================] - 0s 213us/step - loss: 0.6419 - val_loss: 0.7865\n",
      "Epoch 73/400\n",
      "192/192 [==============================] - 0s 197us/step - loss: 0.7862 - val_loss: 0.6436\n",
      "Epoch 74/400\n",
      "192/192 [==============================] - 0s 192us/step - loss: 0.6058 - val_loss: 0.6221\n",
      "Epoch 75/400\n",
      "192/192 [==============================] - 0s 187us/step - loss: 0.6002 - val_loss: 0.6498\n",
      "Epoch 76/400\n",
      "192/192 [==============================] - 0s 171us/step - loss: 0.6110 - val_loss: 0.6530\n",
      "Epoch 77/400\n",
      "192/192 [==============================] - 0s 218us/step - loss: 0.6166 - val_loss: 0.7106\n",
      "Epoch 78/400\n",
      "192/192 [==============================] - 0s 249us/step - loss: 0.7129 - val_loss: 0.6164\n",
      "Epoch 79/400\n",
      "192/192 [==============================] - 0s 187us/step - loss: 0.6092 - val_loss: 0.6678\n",
      "Epoch 80/400\n",
      "192/192 [==============================] - 0s 197us/step - loss: 0.6404 - val_loss: 0.6500\n",
      "Epoch 81/400\n",
      "192/192 [==============================] - 0s 213us/step - loss: 0.6871 - val_loss: 0.6675\n",
      "Epoch 82/400\n",
      "192/192 [==============================] - 0s 234us/step - loss: 0.6588 - val_loss: 0.7014\n",
      "Epoch 83/400\n",
      "192/192 [==============================] - 0s 301us/step - loss: 0.6832 - val_loss: 0.6173\n",
      "Epoch 84/400\n",
      "192/192 [==============================] - 0s 255us/step - loss: 0.5826 - val_loss: 0.6107\n",
      "Epoch 85/400\n",
      "192/192 [==============================] - 0s 270us/step - loss: 0.5886 - val_loss: 0.6091\n",
      "Epoch 86/400\n",
      "192/192 [==============================] - 0s 364us/step - loss: 0.6091 - val_loss: 0.6057\n",
      "Epoch 87/400\n",
      "192/192 [==============================] - 0s 296us/step - loss: 0.5942 - val_loss: 0.6063\n",
      "Epoch 88/400\n",
      "192/192 [==============================] - 0s 540us/step - loss: 0.6075 - val_loss: 0.6427\n",
      "Epoch 89/400\n",
      "192/192 [==============================] - 0s 275us/step - loss: 0.6737 - val_loss: 0.6514\n",
      "Epoch 90/400\n",
      "192/192 [==============================] - 0s 379us/step - loss: 0.6510 - val_loss: 0.6063\n",
      "Epoch 91/400\n",
      "192/192 [==============================] - 0s 343us/step - loss: 0.5666 - val_loss: 0.6202\n",
      "Epoch 92/400\n",
      "192/192 [==============================] - 0s 343us/step - loss: 0.6062 - val_loss: 0.6187\n",
      "Epoch 93/400\n",
      "192/192 [==============================] - 0s 436us/step - loss: 0.6177 - val_loss: 0.6621\n",
      "Epoch 94/400\n",
      "192/192 [==============================] - 0s 327us/step - loss: 0.6199 - val_loss: 0.6501\n",
      "Epoch 95/400\n",
      "192/192 [==============================] - 0s 405us/step - loss: 0.5932 - val_loss: 0.6603\n",
      "Epoch 96/400\n",
      "192/192 [==============================] - 0s 327us/step - loss: 0.6006 - val_loss: 0.6124\n",
      "Epoch 97/400\n",
      "192/192 [==============================] - 0s 218us/step - loss: 0.5410 - val_loss: 0.6409\n",
      "Epoch 98/400\n",
      "192/192 [==============================] - 0s 166us/step - loss: 0.5716 - val_loss: 0.6405\n",
      "Epoch 99/400\n",
      "192/192 [==============================] - 0s 229us/step - loss: 0.5705 - val_loss: 0.6258\n",
      "Epoch 100/400\n",
      "192/192 [==============================] - 0s 353us/step - loss: 0.5803 - val_loss: 0.6627\n",
      "Epoch 101/400\n",
      "192/192 [==============================] - 0s 239us/step - loss: 0.5819 - val_loss: 0.6081\n",
      "Epoch 102/400\n",
      "192/192 [==============================] - 0s 265us/step - loss: 0.5390 - val_loss: 0.6770\n",
      "Epoch 103/400\n",
      "192/192 [==============================] - 0s 286us/step - loss: 0.6291 - val_loss: 0.5922\n",
      "Epoch 104/400\n",
      "192/192 [==============================] - 0s 249us/step - loss: 0.5423 - val_loss: 0.6210\n",
      "Epoch 105/400\n",
      "192/192 [==============================] - 0s 244us/step - loss: 0.5469 - val_loss: 0.6788\n",
      "Epoch 106/400\n",
      "192/192 [==============================] - 0s 218us/step - loss: 0.6213 - val_loss: 0.5822\n",
      "Epoch 107/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.5442 - val_loss: 0.6305\n",
      "Epoch 108/400\n",
      "192/192 [==============================] - 0s 197us/step - loss: 0.5998 - val_loss: 0.5952\n",
      "Epoch 109/400\n",
      "192/192 [==============================] - 0s 171us/step - loss: 0.5429 - val_loss: 0.5986\n",
      "Epoch 110/400\n",
      "192/192 [==============================] - 0s 223us/step - loss: 0.5276 - val_loss: 0.6032\n",
      "Epoch 111/400\n",
      "192/192 [==============================] - 0s 239us/step - loss: 0.5363 - val_loss: 0.6272\n",
      "Epoch 112/400\n",
      "192/192 [==============================] - 0s 187us/step - loss: 0.5512 - val_loss: 0.5888\n",
      "Epoch 113/400\n",
      "192/192 [==============================] - 0s 223us/step - loss: 0.5474 - val_loss: 0.6770\n",
      "Epoch 114/400\n",
      "192/192 [==============================] - 0s 192us/step - loss: 0.5704 - val_loss: 0.5730\n",
      "Epoch 115/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.4984 - val_loss: 0.5993\n",
      "Epoch 116/400\n",
      "192/192 [==============================] - 0s 239us/step - loss: 0.5376 - val_loss: 0.6493\n",
      "Epoch 117/400\n",
      "192/192 [==============================] - 0s 223us/step - loss: 0.5957 - val_loss: 0.5675\n",
      "Epoch 118/400\n",
      "192/192 [==============================] - 0s 260us/step - loss: 0.4818 - val_loss: 0.5771\n",
      "Epoch 119/400\n",
      "192/192 [==============================] - 0s 338us/step - loss: 0.4877 - val_loss: 0.6529\n",
      "Epoch 120/400\n",
      "192/192 [==============================] - 0s 327us/step - loss: 0.6104 - val_loss: 0.6145\n",
      "Epoch 121/400\n",
      "192/192 [==============================] - 0s 416us/step - loss: 0.5435 - val_loss: 0.5913\n",
      "Epoch 122/400\n",
      "192/192 [==============================] - 0s 270us/step - loss: 0.5236 - val_loss: 0.5879\n",
      "Epoch 123/400\n",
      "192/192 [==============================] - 0s 312us/step - loss: 0.5121 - val_loss: 0.5689\n",
      "Epoch 124/400\n",
      "192/192 [==============================] - 0s 260us/step - loss: 0.4818 - val_loss: 0.5888\n",
      "Epoch 125/400\n",
      "192/192 [==============================] - 0s 374us/step - loss: 0.5406 - val_loss: 0.6961\n",
      "Epoch 126/400\n",
      "192/192 [==============================] - 0s 343us/step - loss: 0.6160 - val_loss: 0.5673\n",
      "Epoch 127/400\n",
      "192/192 [==============================] - 0s 410us/step - loss: 0.4636 - val_loss: 0.5790\n",
      "Epoch 128/400\n",
      "192/192 [==============================] - 0s 255us/step - loss: 0.4724 - val_loss: 0.5909\n",
      "Epoch 129/400\n",
      "192/192 [==============================] - 0s 332us/step - loss: 0.5613 - val_loss: 0.6092\n",
      "Epoch 130/400\n",
      "192/192 [==============================] - 0s 281us/step - loss: 0.5384 - val_loss: 0.6426\n",
      "Epoch 131/400\n",
      "192/192 [==============================] - 0s 218us/step - loss: 0.5928 - val_loss: 0.5824\n",
      "Epoch 132/400\n",
      "192/192 [==============================] - 0s 265us/step - loss: 0.5330 - val_loss: 0.5650\n",
      "Epoch 133/400\n",
      "192/192 [==============================] - 0s 156us/step - loss: 0.4729 - val_loss: 0.5777\n",
      "Epoch 134/400\n",
      "192/192 [==============================] - 0s 234us/step - loss: 0.4814 - val_loss: 0.5731\n",
      "Epoch 135/400\n",
      "192/192 [==============================] - 0s 197us/step - loss: 0.4754 - val_loss: 0.5693\n",
      "Epoch 136/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 0s 223us/step - loss: 0.4475 - val_loss: 0.5565\n",
      "Epoch 137/400\n",
      "192/192 [==============================] - 0s 171us/step - loss: 0.4846 - val_loss: 0.6157\n",
      "Epoch 138/400\n",
      "192/192 [==============================] - 0s 203us/step - loss: 0.5669 - val_loss: 0.6383\n",
      "Epoch 139/400\n",
      "192/192 [==============================] - 0s 166us/step - loss: 0.5468 - val_loss: 0.5805\n",
      "Epoch 140/400\n",
      "192/192 [==============================] - 0s 156us/step - loss: 0.4742 - val_loss: 0.6176\n",
      "Epoch 141/400\n",
      "192/192 [==============================] - 0s 166us/step - loss: 0.5349 - val_loss: 0.5609\n",
      "Epoch 142/400\n",
      "192/192 [==============================] - 0s 166us/step - loss: 0.4284 - val_loss: 0.5768\n",
      "Epoch 143/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.4731 - val_loss: 0.5777\n",
      "Epoch 144/400\n",
      "192/192 [==============================] - 0s 229us/step - loss: 0.5052 - val_loss: 0.5869\n",
      "Epoch 145/400\n",
      "192/192 [==============================] - 0s 213us/step - loss: 0.4910 - val_loss: 0.5819\n",
      "Epoch 146/400\n",
      "192/192 [==============================] - 0s 171us/step - loss: 0.5208 - val_loss: 0.5538\n",
      "Epoch 147/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.4693 - val_loss: 0.5927\n",
      "Epoch 148/400\n",
      "192/192 [==============================] - 0s 260us/step - loss: 0.5017 - val_loss: 0.5394\n",
      "Epoch 149/400\n",
      "192/192 [==============================] - 0s 145us/step - loss: 0.4595 - val_loss: 0.6326\n",
      "Epoch 150/400\n",
      "192/192 [==============================] - 0s 177us/step - loss: 0.5853 - val_loss: 0.5605\n",
      "Epoch 151/400\n",
      "192/192 [==============================] - 0s 192us/step - loss: 0.4799 - val_loss: 0.5629\n",
      "Epoch 152/400\n",
      "192/192 [==============================] - 0s 353us/step - loss: 0.4373 - val_loss: 0.5544\n",
      "Epoch 153/400\n",
      "192/192 [==============================] - 0s 197us/step - loss: 0.4630 - val_loss: 0.5920\n",
      "Epoch 154/400\n",
      "192/192 [==============================] - 0s 234us/step - loss: 0.5177 - val_loss: 0.5650\n",
      "Epoch 155/400\n",
      "192/192 [==============================] - 0s 244us/step - loss: 0.4583 - val_loss: 0.5556\n",
      "Epoch 156/400\n",
      "192/192 [==============================] - 0s 291us/step - loss: 0.4505 - val_loss: 0.5757\n",
      "Epoch 157/400\n",
      "192/192 [==============================] - 0s 275us/step - loss: 0.5064 - val_loss: 0.5459\n",
      "Epoch 158/400\n",
      "192/192 [==============================] - 0s 197us/step - loss: 0.4402 - val_loss: 0.5701\n",
      "Epoch 159/400\n",
      "192/192 [==============================] - 0s 364us/step - loss: 0.4731 - val_loss: 0.5530\n",
      "Epoch 160/400\n",
      "192/192 [==============================] - 0s 353us/step - loss: 0.4523 - val_loss: 0.5791\n",
      "Epoch 161/400\n",
      "192/192 [==============================] - 0s 296us/step - loss: 0.4593 - val_loss: 0.5443\n",
      "Epoch 162/400\n",
      "192/192 [==============================] - 0s 286us/step - loss: 0.4092 - val_loss: 0.5551\n",
      "Epoch 163/400\n",
      "192/192 [==============================] - 0s 249us/step - loss: 0.4553 - val_loss: 0.5607\n",
      "Epoch 164/400\n",
      "192/192 [==============================] - 0s 286us/step - loss: 0.4735 - val_loss: 0.5556\n",
      "Epoch 165/400\n",
      "192/192 [==============================] - 0s 249us/step - loss: 0.4194 - val_loss: 0.5487\n",
      "Epoch 166/400\n",
      "192/192 [==============================] - 0s 306us/step - loss: 0.4417 - val_loss: 0.6009\n",
      "Epoch 167/400\n",
      "192/192 [==============================] - 0s 166us/step - loss: 0.5220 - val_loss: 0.5593\n",
      "Epoch 168/400\n",
      "192/192 [==============================] - 0s 171us/step - loss: 0.4519 - val_loss: 0.5561\n",
      "Epoch 169/400\n",
      "192/192 [==============================] - 0s 177us/step - loss: 0.4466 - val_loss: 0.6037\n",
      "Epoch 170/400\n",
      "192/192 [==============================] - 0s 244us/step - loss: 0.4950 - val_loss: 0.6025\n",
      "Epoch 171/400\n",
      "192/192 [==============================] - 0s 192us/step - loss: 0.4869 - val_loss: 0.5475\n",
      "Epoch 172/400\n",
      "192/192 [==============================] - 0s 161us/step - loss: 0.3858 - val_loss: 0.5540\n",
      "Epoch 173/400\n",
      "192/192 [==============================] - 0s 197us/step - loss: 0.3810 - val_loss: 0.5623\n",
      "Epoch 174/400\n",
      "192/192 [==============================] - 0s 192us/step - loss: 0.4410 - val_loss: 0.5698\n",
      "Epoch 175/400\n",
      "192/192 [==============================] - 0s 327us/step - loss: 0.4815 - val_loss: 0.5607\n",
      "Epoch 176/400\n",
      "192/192 [==============================] - 0s 255us/step - loss: 0.4118 - val_loss: 0.5445\n",
      "Epoch 177/400\n",
      "192/192 [==============================] - 0s 270us/step - loss: 0.3713 - val_loss: 0.5368\n",
      "Epoch 178/400\n",
      "192/192 [==============================] - 0s 312us/step - loss: 0.3668 - val_loss: 0.5403\n",
      "Epoch 179/400\n",
      "192/192 [==============================] - 0s 208us/step - loss: 0.3590 - val_loss: 0.6143\n",
      "Epoch 180/400\n",
      "192/192 [==============================] - 0s 255us/step - loss: 0.5541 - val_loss: 0.6444\n",
      "Epoch 181/400\n",
      "192/192 [==============================] - 0s 338us/step - loss: 0.5459 - val_loss: 0.5746\n",
      "Epoch 182/400\n",
      "192/192 [==============================] - 0s 296us/step - loss: 0.4381 - val_loss: 0.5640\n",
      "Epoch 183/400\n",
      "192/192 [==============================] - 0s 234us/step - loss: 0.4287 - val_loss: 0.6107\n",
      "Epoch 184/400\n",
      "192/192 [==============================] - 0s 229us/step - loss: 0.4771 - val_loss: 0.5467\n",
      "Epoch 185/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.3785 - val_loss: 0.5467\n",
      "Epoch 186/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.3812 - val_loss: 0.6183\n",
      "Epoch 187/400\n",
      "192/192 [==============================] - 0s 187us/step - loss: 0.4840 - val_loss: 0.5519\n",
      "Epoch 188/400\n",
      "192/192 [==============================] - 0s 192us/step - loss: 0.3560 - val_loss: 0.6047\n",
      "Epoch 189/400\n",
      "192/192 [==============================] - 0s 691us/step - loss: 0.5076 - val_loss: 0.5892\n",
      "Epoch 190/400\n",
      "192/192 [==============================] - 0s 275us/step - loss: 0.4543 - val_loss: 0.5964\n",
      "Epoch 191/400\n",
      "192/192 [==============================] - 0s 379us/step - loss: 0.4445 - val_loss: 0.5883\n",
      "Epoch 192/400\n",
      "192/192 [==============================] - 0s 187us/step - loss: 0.4313 - val_loss: 0.5754\n",
      "Epoch 193/400\n",
      "192/192 [==============================] - 0s 229us/step - loss: 0.4190 - val_loss: 0.5882\n",
      "Epoch 194/400\n",
      "192/192 [==============================] - 0s 166us/step - loss: 0.4262 - val_loss: 0.5897\n",
      "Epoch 195/400\n",
      "192/192 [==============================] - 0s 171us/step - loss: 0.4395 - val_loss: 0.5929\n",
      "Epoch 196/400\n",
      "192/192 [==============================] - 0s 187us/step - loss: 0.4360 - val_loss: 0.5681\n",
      "Epoch 197/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.3563 - val_loss: 0.5592\n",
      "Epoch 198/400\n",
      "192/192 [==============================] - 0s 161us/step - loss: 0.3305 - val_loss: 0.5756\n",
      "Epoch 199/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.3757 - val_loss: 0.5876\n",
      "Epoch 200/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.4553 - val_loss: 0.5916\n",
      "Epoch 201/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.4227 - val_loss: 0.5883\n",
      "Epoch 202/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.4413 - val_loss: 0.5688\n",
      "Epoch 203/400\n",
      "192/192 [==============================] - 0s 156us/step - loss: 0.4067 - val_loss: 0.6046\n",
      "Epoch 204/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.4287 - val_loss: 0.5988\n",
      "Epoch 205/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.4091 - val_loss: 0.5962\n",
      "Epoch 206/400\n",
      "192/192 [==============================] - 0s 151us/step - loss: 0.3883 - val_loss: 0.5822\n",
      "Epoch 207/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.3898 - val_loss: 0.6130\n",
      "Epoch 208/400\n",
      "192/192 [==============================] - 0s 140us/step - loss: 0.4490 - val_loss: 0.5858\n",
      "Epoch 209/400\n",
      "192/192 [==============================] - 0s 166us/step - loss: 0.4006 - val_loss: 0.5852\n",
      "Epoch 210/400\n",
      "192/192 [==============================] - 0s 156us/step - loss: 0.3975 - val_loss: 0.5880\n",
      "Epoch 211/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.3984 - val_loss: 0.5962\n",
      "Epoch 212/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.4178 - val_loss: 0.5909\n",
      "Epoch 213/400\n",
      "192/192 [==============================] - 0s 151us/step - loss: 0.4014 - val_loss: 0.5805\n",
      "Epoch 214/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 0s 140us/step - loss: 0.3539 - val_loss: 0.5928\n",
      "Epoch 215/400\n",
      "192/192 [==============================] - ETA: 0s - loss: 0.448 - 0s 151us/step - loss: 0.4306 - val_loss: 0.5767\n",
      "Epoch 216/400\n",
      "192/192 [==============================] - 0s 166us/step - loss: 0.3900 - val_loss: 0.5722\n",
      "Epoch 217/400\n",
      "192/192 [==============================] - 0s 166us/step - loss: 0.3647 - val_loss: 0.5879\n",
      "Epoch 218/400\n",
      "192/192 [==============================] - ETA: 0s - loss: 0.432 - 0s 177us/step - loss: 0.3785 - val_loss: 0.5825\n",
      "Epoch 219/400\n",
      "192/192 [==============================] - 0s 192us/step - loss: 0.3514 - val_loss: 0.6013\n",
      "Epoch 220/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.4228 - val_loss: 0.6114\n",
      "Epoch 221/400\n",
      "192/192 [==============================] - 0s 140us/step - loss: 0.3954 - val_loss: 0.6064\n",
      "Epoch 222/400\n",
      "192/192 [==============================] - 0s 140us/step - loss: 0.3771 - val_loss: 0.5936\n",
      "Epoch 223/400\n",
      "192/192 [==============================] - 0s 135us/step - loss: 0.3692 - val_loss: 0.5959\n",
      "Epoch 224/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.4015 - val_loss: 0.6095\n",
      "Epoch 225/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.4075 - val_loss: 0.5929\n",
      "Epoch 226/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.3852 - val_loss: 0.6353\n",
      "Epoch 227/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.4224 - val_loss: 0.6106\n",
      "Epoch 228/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.3748 - val_loss: 0.5886\n",
      "Epoch 229/400\n",
      "192/192 [==============================] - 0s 421us/step - loss: 0.3319 - val_loss: 0.6144\n",
      "Epoch 230/400\n",
      "192/192 [==============================] - 0s 255us/step - loss: 0.4276 - val_loss: 0.6027\n",
      "Epoch 231/400\n",
      "192/192 [==============================] - 0s 156us/step - loss: 0.3584 - val_loss: 0.6038\n",
      "Epoch 232/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.3893 - val_loss: 0.5769\n",
      "Epoch 233/400\n",
      "192/192 [==============================] - 0s 109us/step - loss: 0.3613 - val_loss: 0.5908\n",
      "Epoch 234/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.2792 - val_loss: 0.5739\n",
      "Epoch 235/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.3705 - val_loss: 0.6242\n",
      "Epoch 236/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.4229 - val_loss: 0.6102\n",
      "Epoch 237/400\n",
      "192/192 [==============================] - 0s 145us/step - loss: 0.3911 - val_loss: 0.5941\n",
      "Epoch 238/400\n",
      "192/192 [==============================] - 0s 208us/step - loss: 0.3769 - val_loss: 0.6155\n",
      "Epoch 239/400\n",
      "192/192 [==============================] - 0s 145us/step - loss: 0.3795 - val_loss: 0.5959\n",
      "Epoch 240/400\n",
      "192/192 [==============================] - 0s 109us/step - loss: 0.3226 - val_loss: 0.5940\n",
      "Epoch 241/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.3440 - val_loss: 0.6181\n",
      "Epoch 242/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.3749 - val_loss: 0.6178\n",
      "Epoch 243/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.3771 - val_loss: 0.6123\n",
      "Epoch 244/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.3523 - val_loss: 0.6175\n",
      "Epoch 245/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.3049 - val_loss: 0.6057\n",
      "Epoch 246/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.3420 - val_loss: 0.6262\n",
      "Epoch 247/400\n",
      "192/192 [==============================] - 0s 171us/step - loss: 0.3965 - val_loss: 0.5972\n",
      "Epoch 248/400\n",
      "192/192 [==============================] - 0s 161us/step - loss: 0.3236 - val_loss: 0.6170\n",
      "Epoch 249/400\n",
      "192/192 [==============================] - 0s 140us/step - loss: 0.3705 - val_loss: 0.6265\n",
      "Epoch 250/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.3959 - val_loss: 0.6255\n",
      "Epoch 251/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.3696 - val_loss: 0.6076\n",
      "Epoch 252/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.3013 - val_loss: 0.6185\n",
      "Epoch 253/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.2597 - val_loss: 0.6228\n",
      "Epoch 254/400\n",
      "192/192 [==============================] - 0s 135us/step - loss: 0.3122 - val_loss: 0.6668\n",
      "Epoch 255/400\n",
      "192/192 [==============================] - 0s 161us/step - loss: 0.4241 - val_loss: 0.6177\n",
      "Epoch 256/400\n",
      "192/192 [==============================] - 0s 151us/step - loss: 0.2444 - val_loss: 0.6149\n",
      "Epoch 257/400\n",
      "192/192 [==============================] - 0s 145us/step - loss: 0.2973 - val_loss: 0.6473\n",
      "Epoch 258/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.3926 - val_loss: 0.6479\n",
      "Epoch 259/400\n",
      "192/192 [==============================] - 0s 109us/step - loss: 0.3241 - val_loss: 0.6337\n",
      "Epoch 260/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.3210 - val_loss: 0.6362\n",
      "Epoch 261/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.3579 - val_loss: 0.6469\n",
      "Epoch 262/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.3503 - val_loss: 0.6504\n",
      "Epoch 263/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.3209 - val_loss: 0.6414\n",
      "Epoch 264/400\n",
      "192/192 [==============================] - 0s 135us/step - loss: 0.3344 - val_loss: 0.6353\n",
      "Epoch 265/400\n",
      "192/192 [==============================] - 0s 135us/step - loss: 0.3350 - val_loss: 0.6358\n",
      "Epoch 266/400\n",
      "192/192 [==============================] - 0s 218us/step - loss: 0.2888 - val_loss: 0.6413\n",
      "Epoch 267/400\n",
      "192/192 [==============================] - 0s 140us/step - loss: 0.3495 - val_loss: 0.6405\n",
      "Epoch 268/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.3261 - val_loss: 0.6450\n",
      "Epoch 269/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2903 - val_loss: 0.6406\n",
      "Epoch 270/400\n",
      "192/192 [==============================] - 0s 109us/step - loss: 0.3397 - val_loss: 0.6501\n",
      "Epoch 271/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.3281 - val_loss: 0.6474\n",
      "Epoch 272/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.2421 - val_loss: 0.6470\n",
      "Epoch 273/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2393 - val_loss: 0.6676\n",
      "Epoch 274/400\n",
      "192/192 [==============================] - 0s 140us/step - loss: 0.4020 - val_loss: 0.6521\n",
      "Epoch 275/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.3311 - val_loss: 0.6374\n",
      "Epoch 276/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.3199 - val_loss: 0.6495\n",
      "Epoch 277/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.3109 - val_loss: 0.6395\n",
      "Epoch 278/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.2719 - val_loss: 0.6507\n",
      "Epoch 279/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.3372 - val_loss: 0.6597\n",
      "Epoch 280/400\n",
      "192/192 [==============================] - 0s 213us/step - loss: 0.3367 - val_loss: 0.6456\n",
      "Epoch 281/400\n",
      "192/192 [==============================] - 0s 301us/step - loss: 0.2589 - val_loss: 0.6640\n",
      "Epoch 282/400\n",
      "192/192 [==============================] - 0s 197us/step - loss: 0.3385 - val_loss: 0.6648\n",
      "Epoch 283/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.3104 - val_loss: 0.6612\n",
      "Epoch 284/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.3283 - val_loss: 0.6451\n",
      "Epoch 285/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.3007 - val_loss: 0.6483\n",
      "Epoch 286/400\n",
      "192/192 [==============================] - 0s 109us/step - loss: 0.3062 - val_loss: 0.6381\n",
      "Epoch 287/400\n",
      "192/192 [==============================] - 0s 109us/step - loss: 0.2956 - val_loss: 0.6439\n",
      "Epoch 288/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.3294 - val_loss: 0.6478\n",
      "Epoch 289/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2581 - val_loss: 0.6490\n",
      "Epoch 290/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.3255 - val_loss: 0.6482\n",
      "Epoch 291/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 0s 151us/step - loss: 0.3089 - val_loss: 0.6543\n",
      "Epoch 292/400\n",
      "192/192 [==============================] - 0s 177us/step - loss: 0.1981 - val_loss: 0.6578\n",
      "Epoch 293/400\n",
      "192/192 [==============================] - 0s 161us/step - loss: 0.1869 - val_loss: 0.6895\n",
      "Epoch 294/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.3487 - val_loss: 0.6697\n",
      "Epoch 295/400\n",
      "192/192 [==============================] - 0s 135us/step - loss: 0.2802 - val_loss: 0.6943\n",
      "Epoch 296/400\n",
      "192/192 [==============================] - 0s 109us/step - loss: 0.2697 - val_loss: 0.7211\n",
      "Epoch 297/400\n",
      "192/192 [==============================] - 0s 109us/step - loss: 0.3493 - val_loss: 0.6899\n",
      "Epoch 298/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.3005 - val_loss: 0.6871\n",
      "Epoch 299/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2932 - val_loss: 0.6704\n",
      "Epoch 300/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.2787 - val_loss: 0.6595\n",
      "Epoch 301/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.2511 - val_loss: 0.6738\n",
      "Epoch 302/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2759 - val_loss: 0.6564\n",
      "Epoch 303/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.2688 - val_loss: 0.6517\n",
      "Epoch 304/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2304 - val_loss: 0.6617\n",
      "Epoch 305/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.2620 - val_loss: 0.6981\n",
      "Epoch 306/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.3385 - val_loss: 0.6540\n",
      "Epoch 307/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2144 - val_loss: 0.7023\n",
      "Epoch 308/400\n",
      "192/192 [==============================] - 0s 140us/step - loss: 0.3249 - val_loss: 0.6919\n",
      "Epoch 309/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2993 - val_loss: 0.6672\n",
      "Epoch 310/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.2913 - val_loss: 0.6874\n",
      "Epoch 311/400\n",
      "192/192 [==============================] - 0s 151us/step - loss: 0.2899 - val_loss: 0.6735\n",
      "Epoch 312/400\n",
      "192/192 [==============================] - 0s 135us/step - loss: 0.2129 - val_loss: 0.6795\n",
      "Epoch 313/400\n",
      "192/192 [==============================] - 0s 156us/step - loss: 0.2237 - val_loss: 0.6975\n",
      "Epoch 314/400\n",
      "192/192 [==============================] - 0s 145us/step - loss: 0.2997 - val_loss: 0.6748\n",
      "Epoch 315/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2085 - val_loss: 0.6582\n",
      "Epoch 316/400\n",
      "192/192 [==============================] - 0s 135us/step - loss: 0.2196 - val_loss: 0.6914\n",
      "Epoch 317/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.3288 - val_loss: 0.6717\n",
      "Epoch 318/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2743 - val_loss: 0.6644\n",
      "Epoch 319/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2744 - val_loss: 0.7120\n",
      "Epoch 320/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.3061 - val_loss: 0.6776\n",
      "Epoch 321/400\n",
      "192/192 [==============================] - 0s 161us/step - loss: 0.2577 - val_loss: 0.6877\n",
      "Epoch 322/400\n",
      "192/192 [==============================] - 0s 187us/step - loss: 0.2430 - val_loss: 0.6743\n",
      "Epoch 323/400\n",
      "192/192 [==============================] - 0s 192us/step - loss: 0.2826 - val_loss: 0.7017\n",
      "Epoch 324/400\n",
      "192/192 [==============================] - 0s 223us/step - loss: 0.2933 - val_loss: 0.6477\n",
      "Epoch 325/400\n",
      "192/192 [==============================] - 0s 187us/step - loss: 0.2107 - val_loss: 0.6786\n",
      "Epoch 326/400\n",
      "192/192 [==============================] - 0s 197us/step - loss: 0.2782 - val_loss: 0.6785\n",
      "Epoch 327/400\n",
      "192/192 [==============================] - 0s 192us/step - loss: 0.2475 - val_loss: 0.6471\n",
      "Epoch 328/400\n",
      "192/192 [==============================] - 0s 156us/step - loss: 0.1988 - val_loss: 0.6645\n",
      "Epoch 329/400\n",
      "192/192 [==============================] - 0s 161us/step - loss: 0.2508 - val_loss: 0.6679\n",
      "Epoch 330/400\n",
      "192/192 [==============================] - 0s 151us/step - loss: 0.2350 - val_loss: 0.7144\n",
      "Epoch 331/400\n",
      "192/192 [==============================] - 0s 140us/step - loss: 0.3226 - val_loss: 0.6679\n",
      "Epoch 332/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2523 - val_loss: 0.6968\n",
      "Epoch 333/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.2701 - val_loss: 0.6836\n",
      "Epoch 334/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.2641 - val_loss: 0.6821\n",
      "Epoch 335/400\n",
      "192/192 [==============================] - 0s 260us/step - loss: 0.2456 - val_loss: 0.6578\n",
      "Epoch 336/400\n",
      "192/192 [==============================] - 0s 151us/step - loss: 0.2081 - val_loss: 0.6971\n",
      "Epoch 337/400\n",
      "192/192 [==============================] - 0s 156us/step - loss: 0.3171 - val_loss: 0.6595\n",
      "Epoch 338/400\n",
      "192/192 [==============================] - 0s 177us/step - loss: 0.2150 - val_loss: 0.6731\n",
      "Epoch 339/400\n",
      "192/192 [==============================] - 0s 161us/step - loss: 0.2540 - val_loss: 0.6639\n",
      "Epoch 340/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2561 - val_loss: 0.6719\n",
      "Epoch 341/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.2115 - val_loss: 0.6701\n",
      "Epoch 342/400\n",
      "192/192 [==============================] - 0s 109us/step - loss: 0.2537 - val_loss: 0.6689\n",
      "Epoch 343/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.2316 - val_loss: 0.6789\n",
      "Epoch 344/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.2872 - val_loss: 0.6446\n",
      "Epoch 345/400\n",
      "192/192 [==============================] - 0s 244us/step - loss: 0.2437 - val_loss: 0.6624\n",
      "Epoch 346/400\n",
      "192/192 [==============================] - 0s 197us/step - loss: 0.2170 - val_loss: 0.6944\n",
      "Epoch 347/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.2781 - val_loss: 0.6762\n",
      "Epoch 348/400\n",
      "192/192 [==============================] - 0s 182us/step - loss: 0.2198 - val_loss: 0.6887\n",
      "Epoch 349/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.2946 - val_loss: 0.6625\n",
      "Epoch 350/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2392 - val_loss: 0.6894\n",
      "Epoch 351/400\n",
      "192/192 [==============================] - 0s 140us/step - loss: 0.2494 - val_loss: 0.6751\n",
      "Epoch 352/400\n",
      "192/192 [==============================] - 0s 161us/step - loss: 0.2407 - val_loss: 0.6942\n",
      "Epoch 353/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2580 - val_loss: 0.6680\n",
      "Epoch 354/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.1869 - val_loss: 0.6809\n",
      "Epoch 355/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.1828 - val_loss: 0.7100\n",
      "Epoch 356/400\n",
      "192/192 [==============================] - 0s 120us/step - loss: 0.2819 - val_loss: 0.6785\n",
      "Epoch 357/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2028 - val_loss: 0.6725\n",
      "Epoch 358/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.2355 - val_loss: 0.6862\n",
      "Epoch 359/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2707 - val_loss: 0.6792\n",
      "Epoch 360/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2737 - val_loss: 0.6345\n",
      "Epoch 361/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2076 - val_loss: 0.6709\n",
      "Epoch 362/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2690 - val_loss: 0.6755\n",
      "Epoch 363/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2199 - val_loss: 0.6650\n",
      "Epoch 364/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.2085 - val_loss: 0.6720\n",
      "Epoch 365/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2365 - val_loss: 0.7079\n",
      "Epoch 366/400\n",
      "192/192 [==============================] - 0s 135us/step - loss: 0.2893 - val_loss: 0.6655\n",
      "Epoch 367/400\n",
      "192/192 [==============================] - 0s 151us/step - loss: 0.1975 - val_loss: 0.6652\n",
      "Epoch 368/400\n",
      "192/192 [==============================] - 0s 135us/step - loss: 0.2077 - val_loss: 0.7008\n",
      "Epoch 369/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 0s 114us/step - loss: 0.3186 - val_loss: 0.6754\n",
      "Epoch 370/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2488 - val_loss: 0.6609\n",
      "Epoch 371/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2112 - val_loss: 0.6885\n",
      "Epoch 372/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2709 - val_loss: 0.6650\n",
      "Epoch 373/400\n",
      "192/192 [==============================] - 0s 109us/step - loss: 0.2296 - val_loss: 0.6721\n",
      "Epoch 374/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2851 - val_loss: 0.6559\n",
      "Epoch 375/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2097 - val_loss: 0.6638\n",
      "Epoch 376/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.1996 - val_loss: 0.6671\n",
      "Epoch 377/400\n",
      "192/192 [==============================] - 0s 135us/step - loss: 0.2174 - val_loss: 0.6490\n",
      "Epoch 378/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.1676 - val_loss: 0.6727\n",
      "Epoch 379/400\n",
      "192/192 [==============================] - 0s 145us/step - loss: 0.1633 - val_loss: 0.7246\n",
      "Epoch 380/400\n",
      "192/192 [==============================] - 0s 140us/step - loss: 0.3471 - val_loss: 0.6663\n",
      "Epoch 381/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2127 - val_loss: 0.7002\n",
      "Epoch 382/400\n",
      "192/192 [==============================] - 0s 104us/step - loss: 0.2788 - val_loss: 0.6951\n",
      "Epoch 383/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2226 - val_loss: 0.7019\n",
      "Epoch 384/400\n",
      "192/192 [==============================] - 0s 104us/step - loss: 0.2622 - val_loss: 0.7005\n",
      "Epoch 385/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2013 - val_loss: 0.6822\n",
      "Epoch 386/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.2027 - val_loss: 0.6768\n",
      "Epoch 387/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2387 - val_loss: 0.6892\n",
      "Epoch 388/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.2315 - val_loss: 0.7100\n",
      "Epoch 389/400\n",
      "192/192 [==============================] - 0s 135us/step - loss: 0.2615 - val_loss: 0.7059\n",
      "Epoch 390/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.2215 - val_loss: 0.6795\n",
      "Epoch 391/400\n",
      "192/192 [==============================] - 0s 114us/step - loss: 0.2007 - val_loss: 0.6736\n",
      "Epoch 392/400\n",
      "192/192 [==============================] - 0s 119us/step - loss: 0.1802 - val_loss: 0.7144\n",
      "Epoch 393/400\n",
      "192/192 [==============================] - 0s 109us/step - loss: 0.2544 - val_loss: 0.6955\n",
      "Epoch 394/400\n",
      "192/192 [==============================] - 0s 187us/step - loss: 0.2653 - val_loss: 0.6878\n",
      "Epoch 395/400\n",
      "192/192 [==============================] - 0s 125us/step - loss: 0.2316 - val_loss: 0.6837\n",
      "Epoch 396/400\n",
      "192/192 [==============================] - 0s 130us/step - loss: 0.2202 - val_loss: 0.6978\n",
      "Epoch 397/400\n",
      "192/192 [==============================] - 0s 753us/step - loss: 0.2335 - val_loss: 0.6822\n",
      "Epoch 398/400\n",
      "192/192 [==============================] - 0s 369us/step - loss: 0.1864 - val_loss: 0.6883\n",
      "Epoch 399/400\n",
      "192/192 [==============================] - 0s 426us/step - loss: 0.2607 - val_loss: 0.6722\n",
      "Epoch 400/400\n",
      "192/192 [==============================] - 0s 582us/step - loss: 0.2127 - val_loss: 0.7179\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 5, 32)             4224      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 10,497\n",
      "Trainable params: 10,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.731606  7.881605  7.949547  8.2172165 8.330776  8.411415  7.001865\n",
      " 6.1229568 8.232337  8.325524  8.524012  8.288535  8.408112  7.819998\n",
      " 7.2877016 7.4466295 6.916546  8.392839  7.087919  7.980485  7.109317\n",
      " 8.053105  8.40424   6.837388  8.166032  8.896029  7.7428417 8.906673\n",
      " 9.21767   9.540753  6.6982613 8.105751  9.429549  5.162377  8.457841\n",
      " 8.683149  8.787227  9.194319  8.153114  9.482992  9.326212  9.170774\n",
      " 9.510427  8.739231  8.799608  9.243274  8.390653  8.717079  8.518229\n",
      " 9.580307  8.788155  9.199229  9.1769905 9.396189  8.308689  7.492561\n",
      " 8.867543  8.23512   6.0536604 6.315099 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前网络结构预测的TN出水MRE:0.08769181727034377\n",
      "训练集的真值平均值为：8.452500000000002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    当前网络结构预测的TN出水MRE:0.04312339966536906\\n    训练集的真值平均值为：8.36679166666667\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 搭建神经网络\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "model = Sequential()\n",
    "from keras import regularizers\n",
    "'''Simple RNN'''\n",
    "# model.add(layers.SimpleRNN(32, input_shape=(lookback, paranum), activation='sigmoid'))\n",
    "# model.add(layers.SimpleRNN(32, input_shape=(lookback, paranum), activation='sigmoid', dropout=0.2))\n",
    "'''LSTM'''\n",
    "# model.add(layers.LSTM(32, input_shape=(lookback, paranum), activation='sigmoid', dropout=0.2))\n",
    "# model.add(layers.LSTM(32, input_shape=(lookback, paranum), activation='sigmoid'))\n",
    "'''GRU'''\n",
    "# model.add(layers.GRU(16, input_shape=(lookback, paranum), activation='sigmoid',\n",
    "#                      kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model.add(layers.GRU(32, input_shape=(lookback, paranum), activation='sigmoid', dropout=0.2))\n",
    "# model.add(layers.GRU(32, input_shape=(lookback, paranum), activation='sigmoid'))\n",
    "'''带dropout用来削减过拟合的GRU'''\n",
    "# model.add(layers.GRU(16,\n",
    "#                      dropout=0.2,\n",
    "#                      recurrent_dropout=0.2,\n",
    "#                      input_shape=(lookback, paranum),\n",
    "#                      activation='sigmoid'))\n",
    "'''双层LSTM'''\n",
    "# model.add(layers.LSTM(32, input_shape=(lookback, paranum), activation='sigmoid', return_sequences=True))\n",
    "# model.add(layers.LSTM(32, activation='sigmoid'))\n",
    "'''带dropout用来削减过拟合的双层GRU'''\n",
    "# model.add(layers.GRU(32,\n",
    "#                      dropout=0.1,\n",
    "#                      activation='sigmoid',\n",
    "#                      return_sequences=True,\n",
    "#                      input_shape=(lookback, paranum)))\n",
    "# model.add(layers.GRU(32, activation='sigmoid',\n",
    "#                      dropout=0.1))\n",
    "'''无dropout双层GRU'''\n",
    "model.add(layers.GRU(32,\n",
    "                     activation='sigmoid',\n",
    "                     return_sequences=True,\n",
    "                     input_shape=(lookback, paranum)))\n",
    "model.add(layers.GRU(32, activation='sigmoid'))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer=RMSprop(0.01), loss='mae')\n",
    "print(model.summary())\n",
    "history = model.fit(traindata, train_data['TNe'],\n",
    "                    epochs=400,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)\n",
    "print(model.summary())\n",
    "\n",
    "# 可视化训练过程\n",
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylim(0, 2)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#  预测出水////////////////////////////////////////////////////////////////////////////////////////////\n",
    "predictdata = testdata\n",
    "predictnum = testnum\n",
    "predict = model.predict(predictdata).flatten()\n",
    "print(predict)\n",
    "\n",
    "\n",
    "# 结果可视化/////////////////////////////////////////////////////////////////////////////////////////////\n",
    "plt.figure(figsize=(6, 6))\n",
    "true_value = test_data['TNe']\n",
    "plt.scatter(predict, true_value)\n",
    "plt.ylabel('True Values')\n",
    "plt.xlabel('Predictions')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 时序折线图\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(0, predictnum, 1)\n",
    "plt.plot(x,\n",
    "         predict,\n",
    "         linestyle='-',\n",
    "         linewidth=2,\n",
    "         color='#ff9999',\n",
    "         marker=None,\n",
    "         markersize=6,\n",
    "         markeredgecolor='black',\n",
    "         markerfacecolor='#ff9999',\n",
    "         label='predict')\n",
    "plt.plot(x,\n",
    "         true_value,\n",
    "         linestyle='-',\n",
    "         linewidth=2,\n",
    "         color='steelblue',\n",
    "         marker=None,\n",
    "         markersize=6,\n",
    "         markeredgecolor='black',\n",
    "         markerfacecolor='steelblue',\n",
    "         label='actual')\n",
    "\n",
    "# 添加标题和坐标轴标签\n",
    "plt.title('2019predict')\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('TNeffluent')\n",
    "\n",
    "# 显示图例\n",
    "plt.legend()\n",
    "\n",
    "# 剔除图框上边界和右边界的刻度\n",
    "plt.tick_params(top='off', right='off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 计算mre/////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "mre = 0\n",
    "for i in range(len(true_value)):\n",
    "    mre = mre + abs(true_value.iloc[i] - predict[i]) / true_value.iloc[i]\n",
    "    # 这里因为true_value的列表和real_predict的列表格式不同\n",
    "    #  所以计算时，使用了不同的索引级别\n",
    "Mre = mre / len(true_value)\n",
    "print('当前网络结构预测的TN出水MRE:' + str(Mre))\n",
    "print('训练集的真值平均值为：' + str(np.mean(true_value)))\n",
    "\n",
    "'''\n",
    "    当前网络结构预测的TN出水MRE:0.04312339966536906\n",
    "    训练集的真值平均值为：8.36679166666667\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
